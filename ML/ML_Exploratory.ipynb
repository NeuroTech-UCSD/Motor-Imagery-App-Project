{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np                                      # for dealing with data\n",
    "from scipy.signal import butter, sosfiltfilt, sosfreqz  # for filtering\n",
    "import matplotlib.pyplot as plt                         # for plotting\n",
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from generate_epoch import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import KFold\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list_arr = np.array(sorted(listdir('data/train')))\n",
    "total_training_participant = 9\n",
    "trial_per_subj = 3 # 9 x 3 = 27 csv files in total\n",
    "train_list_arr = train_list_arr[1:]\n",
    "train_list_np = np.reshape(train_list_arr, (total_training_participant,trial_per_subj))\n",
    "test_list_arr = np.array(sorted(listdir('data/test')))\n",
    "total_testing_participant = 9\n",
    "test_trial_per_subj = 2\n",
    "test_list_arr = test_list_arr[1:]\n",
    "test_list_np = np.reshape(test_list_arr, (total_testing_participant,test_trial_per_subj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B0101T.csv', 'B0102T.csv', 'B0103T.csv'],\n",
       "       ['B0201T.csv', 'B0202T.csv', 'B0203T.csv'],\n",
       "       ['B0301T.csv', 'B0302T.csv', 'B0303T.csv'],\n",
       "       ['B0401T.csv', 'B0402T.csv', 'B0403T.csv'],\n",
       "       ['B0501T.csv', 'B0502T.csv', 'B0503T.csv'],\n",
       "       ['B0601T.csv', 'B0602T.csv', 'B0603T.csv'],\n",
       "       ['B0701T.csv', 'B0702T.csv', 'B0703T.csv'],\n",
       "       ['B0801T.csv', 'B0802T.csv', 'B0803T.csv'],\n",
       "       ['B0901T.csv', 'B0902T.csv', 'B0903T.csv']], dtype='<U10')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['B0104E.csv', 'B0105E.csv'],\n",
       "       ['B0204E.csv', 'B0205E.csv'],\n",
       "       ['B0304E.csv', 'B0305E.csv'],\n",
       "       ['B0404E.csv', 'B0405E.csv'],\n",
       "       ['B0504E.csv', 'B0505E.csv'],\n",
       "       ['B0604E.csv', 'B0605E.csv'],\n",
       "       ['B0704E.csv', 'B0705E.csv'],\n",
       "       ['B0804E.csv', 'B0805E.csv'],\n",
       "       ['B0904E.csv', 'B0905E.csv']], dtype='<U10')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoching all training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_per_subj = 360\n",
    "stimulus_per_subj_test = 240\n",
    "channels = ['C3','Cz','C4']\n",
    "epoch_s = 0\n",
    "epoch_e = 4000 #4 seconds\n",
    "fs = 250\n",
    "epoch_len = int((abs(epoch_s) + abs(epoch_e)) * (fs / 1000))\n",
    "train_data_list = np.empty((0, stimulus_per_subj, len(channels), epoch_len), float)\n",
    "test_data_list = np.empty((0, stimulus_per_subj_test, len(channels), epoch_len), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order = 2):\n",
    "#     nyq = 0.5 * fs\n",
    "#     low = lowcut / nyq\n",
    "#     high = highcut / nyq\n",
    "#     sos = butter(order, [low, high], analog = False, btype = 'band', output = 'sos')\n",
    "#     filted_data = sosfiltfilt(sos, data)\n",
    "#     return filted_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoched training data shape: (9, 360, 3, 1000)\n",
      "Epoched testing data shape: (9, 240, 3, 1000)\n"
     ]
    }
   ],
   "source": [
    "lowcut = 0.5\n",
    "highcut = 100\n",
    "bl_s = -400\n",
    "bl_e = -300\n",
    "for training_participant_id in range(total_training_participant):\n",
    "    subject_dir_list = train_list_np[training_participant_id]\n",
    "    subject_epoch = np.empty((0, len(channels), epoch_len), float)\n",
    "    for trial_id in range(trial_per_subj):\n",
    "        subject_dir = subject_dir_list[trial_id]\n",
    "        data = generate_epoch(file_path = 'data/train/'+subject_dir, channels = channels, \\\n",
    "                              eeg_filter = butter_bandpass_filter, fs = fs, epoch_s = epoch_s, \\\n",
    "                              epoch_e = epoch_e, bl_s = bl_s, bl_e = bl_e)\n",
    "        subject_epoch = np.vstack((subject_epoch, data))\n",
    "    subject_epoch = np.reshape(subject_epoch, (1, stimulus_per_subj, len(channels), epoch_len))\n",
    "    train_data_list = np.vstack((train_data_list, subject_epoch))\n",
    "\n",
    "print('Epoched training data shape: '+ str(train_data_list.shape))\n",
    "\n",
    "for testing_participant_id in range(total_testing_participant):\n",
    "    subject_dir_list = test_list_np[testing_participant_id]\n",
    "    subject_epoch = np.empty((0, len(channels), epoch_len), float)\n",
    "    for trial_id in range(test_trial_per_subj):\n",
    "        subject_dir = subject_dir_list[trial_id]\n",
    "        data = generate_epoch(file_path = 'data/test/'+subject_dir, channels = channels, \\\n",
    "                              eeg_filter = butter_bandpass_filter, fs = fs, epoch_s = epoch_s, \\\n",
    "                              epoch_e = epoch_e, bl_s = bl_s, bl_e = bl_e)\n",
    "        subject_epoch = np.vstack((subject_epoch, data))\n",
    "    subject_epoch = np.reshape(subject_epoch, (1, stimulus_per_subj_test, len(channels), epoch_len))\n",
    "    test_data_list = np.vstack((test_data_list, subject_epoch))\n",
    "\n",
    "print('Epoched testing data shape: '+ str(test_data_list.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240,)\n",
      "(2160,)\n"
     ]
    }
   ],
   "source": [
    "y = pd.read_csv('data/TrainLabels.csv', header = None)\n",
    "y = y.values.reshape(3240,)\n",
    "print(y.shape)\n",
    "yT = pd.read_csv('data/true_labels.csv', header = None) # put your train label path here\n",
    "yT = yT.values.reshape(2160,)\n",
    "print(yT.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing with XDawn + TangentSpace Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 4, 4)\n",
      "(3240, 10)\n"
     ]
    }
   ],
   "source": [
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "XC = XdawnCovariances(nfilter=1)\n",
    "output = XC.fit_transform(np.reshape(train_data_list, (9*360, 3, 1000)), y)\n",
    "print(output.shape)\n",
    "output = TangentSpace(metric='riemann').fit_transform(output)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2160, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputT = XC.fit_transform(np.reshape(test_data_list, (9*240, 3, 1000)), yT)\n",
    "outputT = TangentSpace(metric='riemann').fit_transform(outputT)\n",
    "outputT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 360, 10) (3, 360, 10)\n"
     ]
    }
   ],
   "source": [
    "X = np.reshape(output, (9, 360, 10))\n",
    "data_train = X[:6]\n",
    "data_test = X[-3:]\n",
    "print(data_train.shape, data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240, 10) (3240,) (2160, 10) (2160,)\n"
     ]
    }
   ],
   "source": [
    "# data split\n",
    "y_train, y_test = np.array([]), np.array([])\n",
    "y_train = y\n",
    "\n",
    "y_test = yT\n",
    "\n",
    "X_train = output\n",
    "\n",
    "X_test = outputT\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70      1080\n",
      "           1       0.70      0.70      0.70      1080\n",
      "\n",
      "    accuracy                           0.70      2160\n",
      "   macro avg       0.70      0.70      0.70      2160\n",
      "weighted avg       0.70      0.70      0.70      2160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# Fit the grid search to the data\n",
    "if not isfile('random_forest_gs'): \n",
    "    rf = RandomForestClassifier()\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "               cv = 4, n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    pickle.dump(grid_search, open('random_forest_gs', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 90, 'max_features': 3, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "grid_search = pickle.load(open('random_forest_gs', 'rb'))\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Predict the probability of our label score\n",
    "Y_pred_proba = grid_search.predict_proba(X_test)\n",
    "\n",
    "r_roc_auc = roc_auc_score(y_test, Y_pred_proba[:,1])\n",
    "fpr, tpr, thresholds = roc_curve(y_test, Y_pred_proba[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='RandomForest (area = %0.2f)' % r_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC of RandomForest (4-fold CV)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.savefig('images2/Randomforest_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    #1ST layer #\n",
    "    [GridSearchCV(LDA(solver='lsqr'),  {'shrinkage': (0.01, 0.1, 1.)}, cv=3, n_jobs=-1),\n",
    "     GridSearchCV(SVC(class_weight='balanced', probability=True),  {'kernel': [\n",
    "                  'rbf'], 'gamma': [10**(-2), 10**(-3)], 'C': [100, 10, 1, 0.1]}, cv=3, n_jobs=-1),\n",
    "     GridSearchCV(LogisticRegression(class_weight='balanced',\n",
    "                                     solver='lbfgs', max_iter=100000), {'C': [100, 10, 1, 0.1]}, cv=3, n_jobs=-1),\n",
    "     LGBMClassifier(boosting_type='gbdt', num_leaves=40, max_depth=-1, learning_rate=0.01, n_estimators=1000, class_weight='balanced', subsample_for_bin=1000, objective=\"xentropy\",\n",
    "                    min_split_gain=0.0, min_child_weight=0.01, min_child_samples=10, subsample=0.9, subsample_freq=1, colsample_bytree=0.5, reg_alpha=0.0, reg_lambda=0.0, random_state=1, n_jobs=1),\n",
    "     GaussianProcessClassifier(),\n",
    "     XGBClassifier(max_depth=5, learning_rate=0.3, reg_lambda=0.1, n_estimators=300,\n",
    "                   objective=\"binary:logistic\", n_jobs=1, booster=\"gblinear\", random_state=1, colsample_bytree=0.4),\n",
    "     XGBClassifier(max_depth=20, learning_rate=0.1, n_estimators=300, objective=\"binary:logistic\",\n",
    "                   n_jobs=1, booster=\"gbtree\", random_state=1, colsample_bytree=0.4),\n",
    "     XGBClassifier(max_depth=100, learning_rate=0.1, n_estimators=300, objective=\"rank:pairwise\",\n",
    "                   n_jobs=1, booster=\"gbtree\", random_state=1, colsample_bytree=0.4),\n",
    "     ],\n",
    "\n",
    "    #2ND layer #\n",
    "    [\n",
    "        RandomForestClassifier(max_depth=50, n_estimators=50),\n",
    "        AdaBoostClassifier(base_estimator=DecisionTreeClassifier(\n",
    "            max_depth=5), n_estimators=200),\n",
    "        ExtraTreesClassifier(max_depth=5, n_estimators=50),\n",
    "    ],\n",
    "\n",
    "    #3RD layer #\n",
    "    [\n",
    "        RandomForestClassifier(\n",
    "            max_depth=5, class_weight='balanced', n_estimators=100),\n",
    "        SVC(kernel='linear', class_weight='balanced', probability=True),\n",
    "        MLPClassifier(hidden_layer_sizes=(32, 16), activation=\"relu\", solver=\"sgd\", alpha=0.01,\n",
    "                      batch_size=30, learning_rate=\"adaptive\", learning_rate_init=0.001, power_t=0.5,\n",
    "                      max_iter=100, shuffle=True, random_state=1, tol=0.0001, nesterovs_momentum=True, momentum=0.9, validation_fraction=0.1, early_stopping=True,\n",
    "                      beta_1=0.1, beta_2=0.1, epsilon=0.1)\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave 4 subject out\n",
    "kf = KFold(4)\n",
    "generator = kf.split(X_train, y_train)\n",
    "\n",
    "# build StackNet\n",
    "stacknet = StackNetClassifier(models, metric=\"auc\", folds=generator, \n",
    "           restacking=False, use_retraining=True, use_proba=True,\n",
    "           n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# make predictions\n",
    "# if not isfile('data/stacknet_prediction.npy'):\n",
    "#     stacknet.fit(X_train, y_train)\n",
    "#     y_probs = stacknet.predict_proba(X_test)[:, 1]\n",
    "#     np.save('data/stacknet_prediction.npy', y_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EEGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import SeparableConv2D, DepthwiseConv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import SpatialDropout2D\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from tensorflow.keras.layers import Input, Flatten\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import utils as np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EEGNet(nb_classes, Chans = 64, Samples = 128, \n",
    "             dropoutRate = 0.5, kernLength = 64, F1 = 8, \n",
    "             D = 2, F2 = 16, norm_rate = 0.25, dropoutType = 'Dropout'):\n",
    "    \"\"\" Keras Implementation of EEGNet\n",
    "    http://iopscience.iop.org/article/10.1088/1741-2552/aace8c/meta\n",
    "\n",
    "    Note that this implements the newest version of EEGNet and NOT the earlier\n",
    "    version (version v1 and v2 on arxiv). We strongly recommend using this\n",
    "    architecture as it performs much better and has nicer properties than\n",
    "    our earlier version. For example:\n",
    "        \n",
    "        1. Depthwise Convolutions to learn spatial filters within a \n",
    "        temporal convolution. The use of the depth_multiplier option maps \n",
    "        exactly to the number of spatial filters learned within a temporal\n",
    "        filter. This matches the setup of algorithms like FBCSP which learn \n",
    "        spatial filters within each filter in a filter-bank. This also limits \n",
    "        the number of free parameters to fit when compared to a fully-connected\n",
    "        convolution. \n",
    "        \n",
    "        2. Separable Convolutions to learn how to optimally combine spatial\n",
    "        filters across temporal bands. Separable Convolutions are Depthwise\n",
    "        Convolutions followed by (1x1) Pointwise Convolutions. \n",
    "        \n",
    "    \n",
    "    While the original paper used Dropout, we found that SpatialDropout2D \n",
    "    sometimes produced slightly better results for classification of ERP \n",
    "    signals. However, SpatialDropout2D significantly reduced performance \n",
    "    on the Oscillatory dataset (SMR, BCI-IV Dataset 2A). We recommend using\n",
    "    the default Dropout in most cases.\n",
    "        \n",
    "    Assumes the input signal is sampled at 128Hz. If you want to use this model\n",
    "    for any other sampling rate you will need to modify the lengths of temporal\n",
    "    kernels and average pooling size in blocks 1 and 2 as needed (double the \n",
    "    kernel lengths for double the sampling rate, etc). Note that we haven't \n",
    "    tested the model performance with this rule so this may not work well. \n",
    "    \n",
    "    The model with default parameters gives the EEGNet-8,2 model as discussed\n",
    "    in the paper. This model should do pretty well in general, although it is\n",
    "\tadvised to do some model searching to get optimal performance on your\n",
    "\tparticular dataset.\n",
    "\n",
    "    We set F2 = F1 * D (number of input filters = number of output filters) for\n",
    "    the SeparableConv2D layer. We haven't extensively tested other values of this\n",
    "    parameter (say, F2 < F1 * D for compressed learning, and F2 > F1 * D for\n",
    "    overcomplete). We believe the main parameters to focus on are F1 and D. \n",
    "\n",
    "    Inputs:\n",
    "        \n",
    "      nb_classes      : int, number of classes to classify\n",
    "      Chans, Samples  : number of channels and time points in the EEG data\n",
    "      dropoutRate     : dropout fraction\n",
    "      kernLength      : length of temporal convolution in first layer. We found\n",
    "                        that setting this to be half the sampling rate worked\n",
    "                        well in practice. For the SMR dataset in particular\n",
    "                        since the data was high-passed at 4Hz we used a kernel\n",
    "                        length of 32.     \n",
    "      F1, F2          : number of temporal filters (F1) and number of pointwise\n",
    "                        filters (F2) to learn. Default: F1 = 8, F2 = F1 * D. \n",
    "      D               : number of spatial filters to learn within each temporal\n",
    "                        convolution. Default: D = 2\n",
    "      dropoutType     : Either SpatialDropout2D or Dropout, passed as a string.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if dropoutType == 'SpatialDropout2D':\n",
    "        dropoutType = SpatialDropout2D\n",
    "    elif dropoutType == 'Dropout':\n",
    "        dropoutType = Dropout\n",
    "    else:\n",
    "        raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                         'or Dropout, passed as a string.')\n",
    "    \n",
    "    input1   = Input(shape = (1, Chans, Samples))\n",
    "\n",
    "    ##################################################################\n",
    "    block1       = Conv2D(F1, (1, kernLength), padding = 'same',\n",
    "                                   input_shape = (1, Chans, Samples),\n",
    "                                   use_bias = False)(input1)\n",
    "    block1       = BatchNormalization(axis = 1)(block1)\n",
    "    block1       = DepthwiseConv2D((Chans, 1), use_bias = False, \n",
    "                                   depth_multiplier = D,\n",
    "                                   depthwise_constraint = max_norm(1.),\n",
    "                                  data_format='channels_first')(block1)\n",
    "    block1       = BatchNormalization(axis = 1)(block1)\n",
    "    block1       = Activation('elu')(block1)\n",
    "    block1       = AveragePooling2D((1, 4), data_format='channels_first')(block1)\n",
    "    block1       = dropoutType(dropoutRate)(block1)\n",
    "    \n",
    "    block2       = SeparableConv2D(F2, (1, 16),\n",
    "                                   use_bias = False, padding = 'same')(block1)\n",
    "    block2       = BatchNormalization(axis = 1)(block2)\n",
    "    block2       = Activation('elu')(block2)\n",
    "    block2       = AveragePooling2D((1, 8), data_format='channels_first')(block2)\n",
    "    block2       = dropoutType(dropoutRate)(block2)\n",
    "        \n",
    "    flatten      = Flatten(name = 'flatten')(block2)\n",
    "    \n",
    "    dense        = Dense(nb_classes, name = 'dense', \n",
    "                         kernel_constraint = max_norm(norm_rate))(flatten)\n",
    "    softmax      = Activation('softmax', name = 'softmax')(dense)\n",
    "    \n",
    "    return Model(inputs=input1, outputs=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (2430, 1, 3, 1000)\n",
      "validation data shape: (810, 1, 3, 1000)\n",
      "testing data shape: (2160, 1, 3, 1000)\n",
      "(2430, 1) (810, 1)\n"
     ]
    }
   ],
   "source": [
    "subj, trial, channel, sample = train_data_list.shape\n",
    "X_train_valid = np.reshape(train_data_list, (-1, 1, channel, sample))\n",
    "X_test = np.reshape(test_data_list, (-1, 1, channel, sample))\n",
    "\n",
    "Y_train_valid = pd.read_csv('data/TrainLabels.csv', header = None).values\n",
    "split_thres = int(subj * trial * 0.25)\n",
    "X_train, X_valid = X_train_valid[split_thres:, :], X_train_valid[:split_thres, :]\n",
    "Y_train, Y_valid = Y_train_valid[split_thres:], Y_train_valid[:split_thres]\n",
    "\n",
    "print('training data shape: ' + str(X_train.shape))\n",
    "print('validation data shape: ' + str(X_valid.shape))\n",
    "print('testing data shape: ' + str(X_test.shape))\n",
    "print(Y_train.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure EEGNET model\n",
    "model = EEGNet(nb_classes=2, Chans=channel, Samples=sample)\n",
    "\n",
    "# compile the model and set the optimizers\n",
    "#sgd = optimizers.SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1, 3, 1000)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1, 3, 8)           512000    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1, 3, 8)           4         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 2, 1, 8)           6         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2, 1, 8)           8         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2, 1, 8)           0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 2, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d (SeparableC (None, 2, 1, 16)          64        \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 1, 16)          8         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 2, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 1, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 512,100\n",
      "Trainable params: 512,090\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set a valid path for your system to record model checkpoints\n",
    "checkpointer = ModelCheckpoint(filepath='/tmp/checkpoint.h5', verbose=1,\n",
    "                               save_best_only=True)\n",
    "# Weighted loss\n",
    "weight_0 = 1/(len([y for y in Y_train_valid if y == 0]))\n",
    "weight_1 = 1/(len([y for y in Y_train_valid if y == 1]))\n",
    "class_weights = {0: weight_0, 1: weight_1}\n",
    "\n",
    "#\n",
    "# # fit the model\n",
    "fittedModel = model.fit(X_train, Y_train, batch_size=32, epochs=100,\n",
    "        verbose=2, validation_data=(X_valid, Y_valid),\n",
    "        callbacks=[checkpointer], class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"# GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
