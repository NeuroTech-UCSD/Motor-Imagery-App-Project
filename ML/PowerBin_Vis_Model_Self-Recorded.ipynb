{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing_helper import * \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import time-frequency functions\n",
    "from neurodsp.timefrequency import amp_by_time, freq_by_time, phase_by_time\n",
    "from neurodsp.plts.time_series import plot_time_series, plot_instantaneous_measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOutputLabelsAndEpochTimes(event_df):\n",
    "    # Generates the ordered list of output labels and epoch time pairs\n",
    "    # Input: event_df -- the event dataframe from the csv file\n",
    "    # Output: \n",
    "    #    output_labels -- [1, 2, 4, 3, etc] where the integers correspond to the trial type encoded\n",
    "    #    epoch_times -- [[<timestamp of start>, <timestamp of end>], [<timestamp of start>, <timestamp of end>], etc]\n",
    "    \n",
    "    output_labels = []\n",
    "    epoch_times = []\n",
    "    current_epoch = []\n",
    "    for index, row in event_df.iterrows():\n",
    "        event_info = row['EventStart'].split(\"_\")\n",
    "        if event_info[0] == 'start': \n",
    "            output_labels.append(int(event_info[1]))\n",
    "            current_epoch.append(row['time'])\n",
    "        else :\n",
    "            current_epoch.append(row['time'])\n",
    "            epoch_times.append(list(current_epoch))\n",
    "            current_epoch = []\n",
    "    return np.array(output_labels), np.array(epoch_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEEGEpochs(epoch_times, eeg_df, target_num_trials=1000):\n",
    "    # Slices and generates the epochs in the eeg_df given the epoch_times\n",
    "    # Input: \n",
    "    #    epoch_times: [[<timestamp of start>, <timestamp of end>], [<timestamp of start>, <timestamp of end>], etc]\n",
    "    #    eeg_df: dataframe from csv file\n",
    "    # Output: \n",
    "    #    a numpy array containing eeg_epochs (#epoch, #chans, #timepoints)\n",
    "    eeg_epochs = []\n",
    "    for epoch_time in epoch_times: \n",
    "        sub_df = eeg_df[(eeg_df['time'] > epoch_time[0]) & (eeg_df['time'] < epoch_time[1])]\n",
    "        sub_df = sub_df.drop(columns=['time'])\n",
    "        num_above = len(sub_df) - target_num_trials\n",
    "        if num_above >= 0:\n",
    "            epoch = np.array(sub_df.values[num_above // 2: len(sub_df) - num_above // 2])[:1000]\n",
    "            eeg_epochs.append(epoch.T)\n",
    "            if len(epoch) != 1000:\n",
    "                print(\"Warning: Potential off by 1 error. Found trail with != 1000 samples:\", len(epoch))\n",
    "        else: \n",
    "            print(\"Warning: Epoch with less than\", target_num_trials, \"eeg samples\")\n",
    "    return np.array(eeg_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogram plotting\n",
    "def plotSpectrogram_fromEEG(eeg_data, fs=eeg_fs, pre_cut_off_freq=0, post_cut_off_freq=120):\n",
    "    f, t, Sxx = signal.spectrogram(eeg_data, fs=fs)\n",
    "    # Calculate the frequency point that corresponds with the desired cut off frequencies\n",
    "    pre_cut = int(len(f)*(pre_cut_off_freq / f[-1]))\n",
    "    post_cut = int(len(f)*(post_cut_off_freq / f[-1]))\n",
    "    plt.pcolormesh(t, f[pre_cut:post_cut], Sxx[pre_cut:post_cut], shading='gouraud')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel(\"Frequency (Hz)\")\n",
    "    plt.xlabel(\"Time (sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading data without EMG\n",
    "eeg_filename = \"./data/self_recorded/eeg_data 15_motorvis.csv\"\n",
    "event_filename = \"./data/self_recorded/event_data 15_motorvis.csv\"\n",
    "\n",
    "eeg_chans = ['C4','C2', 'C1', 'C3']\n",
    "chans = eeg_chans\n",
    "eeg_df = pd.read_csv(eeg_filename)\n",
    "eeg_df.columns=['time','C4', 'C2', 'C1', 'C3']\n",
    "\n",
    "event_df = pd.read_csv(event_filename)\n",
    "event_df.columns=['time', 'EventStart']\n",
    "event_types = {0:\"eye_close\", 1:\"left\", 2:\"right\", 3:\"foot\", 4:\"idle\"}\n",
    "\n",
    "# Filter the full data\n",
    "filtered_df = eeg_df.copy()\n",
    "for chan in chans:\n",
    "    filtered_df[chan] = filterEEG(filtered_df[chan].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Loading data with EMG\n",
    "# eeg_filename = \"./data/self_recorded/eeg_data 15_withEMG.csv\"\n",
    "# event_filename = \"./data/self_recorded/event_data 15_withEMG.csv\"\n",
    "\n",
    "# eeg_chans = ['C4','C2', 'C1', 'C3']\n",
    "# chans = ['EMG_R', 'EMG_L', 'VEOG'] + eeg_chans\n",
    "# eeg_df = pd.read_csv(eeg_filename)\n",
    "# eeg_df.columns=['time'] + chans\n",
    "\n",
    "# event_df = pd.read_csv(event_filename)\n",
    "# event_df.columns=['time', 'EventStart']\n",
    "# event_types = {0:\"eye_close\", 1:\"left\", 2:\"right\", 3:\"foot\", 4:\"idle\"}\n",
    "\n",
    "# # Filter the full data\n",
    "# filtered_df = eeg_df.copy()\n",
    "# for chan in chans:\n",
    "#     filtered_df[chan] = filterEEG(filtered_df[chan].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sampling rate is not conistent between trials\n",
    "plt.plot(np.diff(eeg_df['time'])[:100])\n",
    "plt.axhline(y=1/250, c='black')\n",
    "plt.title(\"Time between samples\")\n",
    "plt.ylabel(\"seconds\")\n",
    "plt.xlabel(\"timepoint\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, the average sampling rate time difference is close enough to 1/250 within 100 samples. \n",
    "np.mean(np.diff(eeg_df['time'])[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexClosest(target_time, eeg_df) :\n",
    "    start_time = eeg_df['time'][0]\n",
    "    elems = eeg_df[np.isclose(target_time-start_time, (eeg_df['time']-start_time).values, atol=1e-04)]\n",
    "    if (len(elems) <= 0): \n",
    "        print(\"Warning: none 1e-04 close\")\n",
    "        elems = eeg_df[np.isclose(target_time-start_time, (eeg_df['time']-start_time).values, atol=1e-03)]\n",
    "    if (len(elems) <= 0): \n",
    "        print(\"Warning: none 1e-03 close\")\n",
    "        elems = eeg_df[np.isclose(target_time-start_time, (eeg_df['time']-start_time).values, atol=1e-02)]\n",
    "    if (len(elems) <= 0): \n",
    "        print(\"Warning: none 1e-02 close\")\n",
    "        return -1\n",
    "    else: \n",
    "        print(\"len elems\", len(elems))\n",
    "        return elems.iloc[0].name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process dfs to get labels, raw eeg epochs, epochs of filtered eeg data, filtered epoch data\n",
    "output_labels, epoch_times = getOutputLabelsAndEpochTimes(event_df)\n",
    "raw_eeg_epochs = getEEGEpochs(epoch_times, eeg_df) # Raw eeg epochs\n",
    "filtered_epochs = getEEGEpochs(epoch_times, filtered_df) # Epoched after filtering\n",
    "\n",
    "# Create DataFrames\n",
    "raw_eeg_epoch_df = getDF(raw_eeg_epochs, output_labels, epoch_times, chans)\n",
    "filtered_epoch_df = getDF(filtered_epochs, output_labels, epoch_times, chans)\n",
    "filtered_epoch_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PSD averages for each channel for each event type (0=left or 1=right)\n",
    "psd_averages_by_type = {}\n",
    "\n",
    "for event_type in event_types.keys(): \n",
    "    psds_only_one_type={}\n",
    "    freqs_only_one_type={}\n",
    "    for i, row in filtered_epoch_df[filtered_epoch_df[\"event_type\"] == event_type].iterrows(): \n",
    "        for ch in eeg_chans: \n",
    "            if ch not in psds_only_one_type: \n",
    "                psds_only_one_type[ch] = list()\n",
    "                freqs_only_one_type[ch] = list()\n",
    "            f, p = getMeanFreqPSD(row[ch])\n",
    "            psds_only_one_type[ch].append(p)\n",
    "            freqs_only_one_type[ch].append(f)\n",
    "    avg_psds_one_type = {}\n",
    "    for ch in eeg_chans:\n",
    "        psds_only_one_type[ch] = np.array(psds_only_one_type[ch])\n",
    "        avg_psds_one_type[ch] = np.mean(psds_only_one_type[ch], axis=0)\n",
    "    psd_averages_by_type[event_type] = dict(avg_psds_one_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Average PSDs\n",
    "for event_type in event_types.keys(): \n",
    "    for ch in eeg_chans[:]: \n",
    "        plotPSD(freqs_only_one_type[eeg_chans[0]][0], psd_averages_by_type[event_type][ch],pre_cut_off_freq=2, post_cut_off_freq=30, label=ch)\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"event type: \" + event_types[event_type])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexClosest(filtered_epoch_df['start_time'][4], eeg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try adjust these variables to see different time ranges! \n",
    "# A single trial is 4 seconds or 1000 timpoints (4 ms per timepoint)\n",
    "# Hint: refer to the Epoched data dataframe for the time of each trial\n",
    "start_time_timepoints = indexClosest(filtered_epoch_df['start_time'][8], eeg_df)\n",
    "end_time_timepoints = start_time_timepoints + 2000 # Specify number of more timepoints we want past start\n",
    "\n",
    "# Plot a single EEG channel\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(filtered_df['C3'].values[start_time_timepoints:end_time_timepoints])\n",
    "plt.title(\"C3 -- \" + str(start_time_timepoints) + \" to \" + str(end_time_timepoints))\n",
    "plt.xlabel(\"timepoints\")\n",
    "plt.ylabel(\"Voltage (uV)\")\n",
    "plt.show()\n",
    "\n",
    "# Plot instananeous alpha amplitude\n",
    "sig = filtered_df['C3'].values[start_time_timepoints:end_time_timepoints]\n",
    "times = filtered_df['time'].values[start_time_timepoints:end_time_timepoints] - filtered_df['time'][0]\n",
    "amp = amp_by_time(sig, eeg_fs, (7, 12))\n",
    "plot_instantaneous_measure(times, [sig, amp], 'amplitude',\n",
    "                           labels=['Raw Signal', 'Amplitude'])\n",
    "\n",
    "# # Plot a single EOG channel\n",
    "# plt.figure(figsize=(15,5))\n",
    "# plt.plot(eeg_df['EOG:ch01'].values[start_time_timepoints:end_time_timepoints])\n",
    "# plt.title(\"EOG:ch01 -- \" + str(start_time_timepoints) + \" to \" + str(end_time_timepoints))\n",
    "# plt.xlabel(\"timepoints\")\n",
    "# plt.ylabel(\"Voltage (uV)\")\n",
    "# plt.show()\n",
    "\n",
    "# Plot the PSD of the single EEG channel\n",
    "plt.figure(figsize=(15,5))\n",
    "plotPSD_fromEEG(filtered_df['C3'].values[start_time_timepoints:end_time_timepoints], pre_cut_off_freq=2, post_cut_off_freq=40,label=\"C3\")\n",
    "plt.title(\"PSD of C3 in the timespan provided\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the spectrogram of the single EEG channel\n",
    "plt.figure(figsize=(15,5))\n",
    "plotSpectrogram_fromEEG(filtered_df['C3'].values[start_time_timepoints:end_time_timepoints], pre_cut_off_freq=2, post_cut_off_freq=40)\n",
    "plt.title(\"Spectrogram of C3 in the timespan provided\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize EEG and PSD for one trial\n",
    "plt.figure(figsize=(15,5))\n",
    "trial_num = 17\n",
    "\n",
    "for ch in eeg_chans: \n",
    "    plt.plot(filtered_epoch_df[ch][trial_num], label=ch)\n",
    "plt.ylabel(\"Voltage (uV)\")\n",
    "plt.xlabel(\"timepoints @ 250Hz\")\n",
    "plt.title(\"EEG of one motor imagery trial\")\n",
    "plt.legend() \n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for ch in eeg_chans: \n",
    "    plotPSD_fromEEG(filtered_epoch_df.iloc[trial_num][ch], pre_cut_off_freq=0.5, post_cut_off_freq=40, label=ch)\n",
    "plt.title(\"PSD of one motor imagery trial\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PSD averages for each channel for each event type \n",
    "# (0 = eye close, 1 = left, 2 = right, 3 = foot, 4 = idle)\n",
    "psd_averages_by_type = {}\n",
    "\n",
    "for event_type in range(0, 5): \n",
    "    psds_only_one_type={}\n",
    "    freqs_only_one_type={}\n",
    "    for i, row in filtered_epoch_df[filtered_epoch_df[\"event_type\"] == event_type].iterrows(): \n",
    "        for ch in chans: \n",
    "            if ch not in psds_only_one_type: \n",
    "                psds_only_one_type[ch] = list()\n",
    "                freqs_only_one_type[ch] = list()\n",
    "            f, p = getMeanFreqPSD(row[ch])\n",
    "            psds_only_one_type[ch].append(p)\n",
    "            freqs_only_one_type[ch].append(f)\n",
    "    avg_psds_one_type = {}\n",
    "    for ch in chans:\n",
    "        psds_only_one_type[ch] = np.array(psds_only_one_type[ch])\n",
    "        avg_psds_one_type[ch] = np.mean(psds_only_one_type[ch], axis=0)\n",
    "    psd_averages_by_type[event_type] = dict(avg_psds_one_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Average PSDs\n",
    "for event_type in range(0, 5): \n",
    "    for ch in ['C4', 'C3']: \n",
    "        plotPSD(freqs_only_one_type[chans[0]][0], psd_averages_by_type[event_type][ch],pre_cut_off_freq=2, post_cut_off_freq=30, label=ch)\n",
    "\n",
    "    # Plot for each event type\n",
    "    plt.legend()\n",
    "    plt.title(\"event type \" + event_types[event_type])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power bin feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyeeg\n",
    "def getPowerRatio(eeg_data, binning, eeg_fs=250):\n",
    "    power, power_ratio = pyeeg.bin_power(eeg_data, binning, eeg_fs)\n",
    "    return np.array(power_ratio)\n",
    "def getIntervals(binning): \n",
    "    intervals = list()\n",
    "    for i, val in enumerate(binning[:-1]): \n",
    "        intervals.append((val, binning[i+1]))\n",
    "    return intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMultipleBarGraphs(bars, bar_width, bar_names, group_names, error_values=None, title=None, xlabel=None, ylabel=None): \n",
    "    if len(bar_names) != len(bars):\n",
    "        print(\"group names must be same length as bars\")\n",
    "        return \n",
    "    # Set position of bar on X axis\n",
    "    positions = list()\n",
    "    positions.append(np.arange(len(bars[0])))\n",
    "    for i, bar in enumerate(bars): \n",
    "        if i>0: \n",
    "            positions.append([x + bar_width for x in positions[i-1]])\n",
    "\n",
    "    # Make the plot\n",
    "    for i, pos in enumerate(positions):\n",
    "        plt.bar(pos, bars[i], width=bar_width, label=bar_names[i])\n",
    "    \n",
    "    if error_values is not None: \n",
    "        for i, pos in enumerate(positions):\n",
    "            plt.errorbar(pos, bars[i], yerr=error_values[i], fmt='.k')\n",
    "    \n",
    "    # Add xticks on the middle of the group bars\n",
    "    if xlabel: \n",
    "        plt.xlabel(xlabel)\n",
    "    if ylabel: \n",
    "        plt.ylabel(ylabel)\n",
    "    if title: \n",
    "        plt.title(title)\n",
    "    plt.xticks([r + bar_width for r in range(len(bars[0]))], group_names)\n",
    "\n",
    "    # Create legend & Show graphic\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the power ratios of each epoch and each eeg channel\n",
    "epoched_df_without_calibration = filtered_epoch_df\n",
    "\n",
    "power_ratios = {'y': []}\n",
    "sub_binning=[0.5, 4, 7, 12, 30]\n",
    "sub_intervals = getIntervals(sub_binning)\n",
    "for i in range(0, len(filtered_epoch_df)): \n",
    "    event_type = filtered_epoch_df['event_type'][i]\n",
    "    for ch in eeg_chans: \n",
    "        ratios = getPowerRatio(filtered_epoch_df[ch][i][100:900], sub_binning)\n",
    "        for j, interval in enumerate(sub_intervals): \n",
    "            key = ch + \"_\" + str(interval)\n",
    "            if key not in power_ratios: \n",
    "                power_ratios[key] = list()\n",
    "            power_ratios[key].append(ratios[j])\n",
    "    power_ratios['y'].append(filtered_epoch_df['event_type'][i])\n",
    "\n",
    "power_ratios_df = pd.DataFrame(power_ratios)\n",
    "bi_class_df = power_ratios_df[(power_ratios_df['y'] == 1) | (power_ratios_df['y'] == 2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard error means between epochs for each channel from the power ratios obtained previously\n",
    "chan_frequency_sems = {}\n",
    "chan_frequency_avgs = {}\n",
    "\n",
    "for event_type in event_types: \n",
    "    for ch in eeg_chans: \n",
    "        for interval in sub_intervals: \n",
    "            key = ch + \"_\" + str(interval)\n",
    "            if key not in chan_frequency_sems: \n",
    "                chan_frequency_sems[key] = list()\n",
    "                chan_frequency_avgs[key] = list()\n",
    "            this_data = power_ratios_df[power_ratios_df['y'] == event_type][key]\n",
    "            sem = np.std(this_data) / np.sqrt(len(this_data))\n",
    "            chan_frequency_sems[key].append(sem)\n",
    "            chan_frequency_avgs[key].append(np.mean(this_data))\n",
    "            \n",
    "std_err_df = pd.DataFrame(chan_frequency_sems)\n",
    "avg_df = pd.DataFrame(chan_frequency_avgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot by channel\n",
    "# rows = intervals, columns = event types\n",
    "\n",
    "for chan in eeg_chans: \n",
    "    chan_of_interest = chan\n",
    "    event_power_ratios = {}\n",
    "    event_sems = {}\n",
    "    power_ratios_for_chan = []\n",
    "    sem_for_chan = []\n",
    "    for event_type in range(1, 5): \n",
    "        if event_type not in event_power_ratios: \n",
    "            event_power_ratios[event_type] = []\n",
    "            event_sems[event_type] = []\n",
    "        for interval in sub_intervals: \n",
    "            key = chan_of_interest + \"_\" + str(interval)\n",
    "            event_power_ratios[event_type].append(avg_df[key][event_type])\n",
    "            event_sems[event_type].append(std_err_df[key][event_type])\n",
    "\n",
    "    event_sems_df = pd.DataFrame(event_sems)\n",
    "    event_power_ratios_df = pd.DataFrame(event_power_ratios)\n",
    "    \n",
    "    plt.title(chan_of_interest)\n",
    "\n",
    "    plotMultipleBarGraphs(np.transpose(np.array(event_power_ratios_df)), 0.15, [1, 2, 3, 4], sub_intervals, error_values=np.transpose(np.array(event_sems_df)))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Bin Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract class\n",
    "class myModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(X, Y):\n",
    "        pass\n",
    "    def predict(X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract trials that are for left vs right hand imagery\n",
    "filtered_epoch_bi_class_df = filtered_epoch_df[(filtered_epoch_df['event_type'] == 1) | (filtered_epoch_df['event_type'] == 2)]\n",
    "X = filtered_epoch_bi_class_df[eeg_chans].values\n",
    "Y = filtered_epoch_bi_class_df['event_type'].values\n",
    "\n",
    "# Split the 4s trials into 2.8s trials. front and end to obtain 2x trials\n",
    "X_split = []\n",
    "Y_split = []\n",
    "for i in range(30): \n",
    "    eeg_data = []\n",
    "    for j in range(4): \n",
    "        eeg_data.append(X[i, j][:700])\n",
    "    eeg_data_2 = []\n",
    "    for j in range(4): \n",
    "        eeg_data_2.append(X[i, j][300:])\n",
    "    \n",
    "    X_split.append(np.array(eeg_data))\n",
    "    X_split.append(np.array(eeg_data_2))\n",
    "    Y_split.append(Y[i])\n",
    "    Y_split.append(Y[i])\n",
    "\n",
    "# Shuffle\n",
    "X = np.array(X_split)\n",
    "Y = np.array(Y_split)\n",
    "temp=list(zip(Y, X))\n",
    "random.shuffle(temp)\n",
    "Y_shuffled, X_shuffled = zip(*temp)\n",
    "\n",
    "# Split train/test\n",
    "num_train = int(len(X_shuffled)*4/(4+1))\n",
    "X_train = np.array(X_shuffled[:num_train])\n",
    "X_test = np.array(X_shuffled[num_train:])\n",
    "Y_train = np.array(Y_shuffled[:num_train])\n",
    "Y_test = np.array(Y_shuffled[num_train:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Bin Model (may have other decision algorithms)\n",
    "class PowerBinModel(myModel): # XDAWN Covariance Preprocessing + Linear Regression Classifier\n",
    "    def __init__(self, chans, num_top=5):\n",
    "        super().__init__()\n",
    "        self.mod_types = [SVC, LinearDiscriminantAnalysis, RandomForestClassifier]\n",
    "        self.mod_type = SVC \n",
    "        self.binning = [0.5, 4, 7, 12, 30]\n",
    "        self.intervals = getIntervals(self.binning)\n",
    "        self.model = self.mod_type()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.chans = chans\n",
    "        self.feat_names = [str(ch) + \"_\" + str(ints) for ch in self.chans for ints in self.intervals]\n",
    "        self.feature_indx = None\n",
    "        self.num_top = num_top\n",
    "        \n",
    "    def getFeatureNames(self):\n",
    "        return self.feat_names\n",
    "        \n",
    "    def _getFeatures(self, eeg_datas) :\n",
    "        feats = []\n",
    "        for eeg_data in eeg_datas: \n",
    "            feats.extend(getPowerRatio(eeg_data, self.binning))\n",
    "        return feats\n",
    "    \n",
    "    def _selectTopFeatures(self, X_features, Y) :\n",
    "        # Get the unique classes of Y to be able to separate the features \n",
    "        unique_Y = np.unique(Y)\n",
    "        X_features_mean = []\n",
    "        for un in unique_Y: \n",
    "            X_features_mean.append(np.mean(X_features[Y == un, :], 0))\n",
    "        X_features_mean_diff = np.diff(X_features_mean, 0)\n",
    "        #X_features_mean_diff = np.mean(X_features_mean_diff, 0)\n",
    "        # Get the index of the sorted mean difference array\n",
    "        args = np.argsort(X_features_mean_diff[0])\n",
    "        # Reverse args to largest features are first\n",
    "        args = args[::-1]\n",
    "        feature_indx = args[:self.num_top]\n",
    "        X_features = np.transpose([X_features[:, i] for i in feature_indx])\n",
    "        return X_features, feature_indx\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.model = self.mod_type()\n",
    "        # X shape must be (#Trials, #Chans, #Timepoints)\n",
    "        # TODO: Add cross validation\n",
    "        # TODO: Add model stacking to training\n",
    "        X_features = np.array([self._getFeatures(eeg_datas) for eeg_datas in X])\n",
    "        X_features, self.feature_indx = self._selectTopFeatures(X_features, Y)\n",
    "        X_features = self.scaler.fit_transform(X_features)\n",
    "        self.model.fit(X_features,Y)\n",
    "    \n",
    "    def evaluate(self, X, Y): \n",
    "        unique_Y = np.unique(Y)\n",
    "        loo = LeaveOneOut()\n",
    "        X_features = np.array([self._getFeatures(eeg_datas) for eeg_datas in X])\n",
    "        accs = [] \n",
    "        for mod in self.mod_types: \n",
    "            y_pred = []\n",
    "            y_true = []\n",
    "            for train_ix, test_ix in loo.split(Y):\n",
    "                # split data\n",
    "                X_train_i, X_test_i = X_features[train_ix, :], X_features[test_ix, :]\n",
    "                y_train_i, y_test_i = Y[train_ix], Y[test_ix]\n",
    "\n",
    "                X_train_i, feature_indx = self._selectTopFeatures(X_train_i, y_train_i)\n",
    "                scaler = StandardScaler()\n",
    "                X_train_i = scaler.fit_transform(X_train_i)\n",
    "\n",
    "                # fit model\n",
    "                model = mod()\n",
    "                model.fit(X_train_i, y_train_i)\n",
    "\n",
    "                X_test_i = np.transpose([X_test_i[:, i] for i in feature_indx])\n",
    "                X_test_i = scaler.transform(X_test_i)\n",
    "\n",
    "                # evaluate model\n",
    "                yhat = model.predict(X_test_i)\n",
    "                # store\n",
    "                y_true.append(y_test_i[0])\n",
    "                y_pred.append(yhat[0])\n",
    "\n",
    "            # calculate accuracy\n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            accs.append(acc)\n",
    "        print(accs)\n",
    "        return max(accs), accs.index(max(accs))\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # X shape must be (#Trials, #Chans, #Timepoints)\n",
    "        X_features = np.array([self._getFeatures(eeg_datas) for eeg_datas in X])\n",
    "        X_features = np.transpose([X_features[:, i] for i in self.feature_indx])\n",
    "        X_features = self.scaler.transform(X_features)\n",
    "        return self.model.predict(X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy on the shuffled train and test split\n",
    "num_feats_used = 4\n",
    "power_bin_model = PowerBinModel(eeg_chans, num_top=15)\n",
    "num_feats = len(power_bin_model.getFeatureNames())\n",
    "print(\"num total feats\", num_feats)\n",
    "print(\"num used\", num_feats_used)\n",
    "power_bin_model.fit(X_train, Y_train)\n",
    "Y_pred = power_bin_model.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", sum(Y_test==Y_pred) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of model as a function of number of features used. \n",
    "# These accuracies are obtained by training the model on everything except one datapoint and then predicting that datapoint. \n",
    "accs = []\n",
    "indxs = []\n",
    "for i in range(1,num_feats) :\n",
    "    power_bin_model = PowerBinModel(eeg_chans, num_top=i)\n",
    "    acc, inx = power_bin_model.evaluate(X, Y)\n",
    "    accs.append(acc)\n",
    "    indxs.append(inx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1,num_feats)), accs)\n",
    "plt.xlabel(\"num features\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(list(range(1,num_feats)), indxs)\n",
    "plt.xlabel(\"num features\")\n",
    "plt.ylabel(\"which model won\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XDawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for models:\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pyriemann.estimation import XdawnCovariances\n",
    "from pyriemann.tangentspace import TangentSpace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays of eeg data (for XDawnModel)\n",
    "start_chan = 0 if filtered_epochs.shape[1] == 4 else 3\n",
    "X = filtered_epochs[3:, start_chan:]\n",
    "Y = output_labels[3:]\n",
    "\n",
    "temp=list(zip(Y, X))\n",
    "random.shuffle(temp)\n",
    "Y_shuffled, X_shuffled = zip(*temp)\n",
    "\n",
    "#Split train/test\n",
    "X_train = np.array(X_shuffled[:int(len(X_shuffled)*4/(4+1))])\n",
    "X_test = np.array(X_shuffled[int(len(X_shuffled)*4/(4+1)):])\n",
    "Y_train = np.array(Y_shuffled[:int(len(Y_shuffled)*4/(4+1))])\n",
    "Y_test = np.array(Y_shuffled[int(len(Y_shuffled)*4/(4+1)):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# XDawn\n",
    "class XDawnLRModel(myModel): # XDAWN Covariance Preprocessing + Linear Regression Classifier\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.XC = XdawnCovariances(nfilter = 1) # the number of filters can be changed\n",
    "        self.logreg = LogisticRegression()\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        X_transformed = self.XC.fit_transform(X, Y)\n",
    "        X_transformed = TangentSpace(metric='riemann').fit_transform(X_transformed)\n",
    "        self.logreg.fit(X_transformed,Y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_transformed = self.XC.transform(X)\n",
    "        X_transformed = TangentSpace(metric='riemann').fit_transform(X_transformed)\n",
    "        return self.logreg.predict(X_transformed)\n",
    "    \n",
    "    def evaluate(self, X, Y): \n",
    "        loo = LeaveOneOut()\n",
    "        X_transformed = self.XC.fit_transform(X, Y)\n",
    "        X_transformed = TangentSpace(metric='riemann').fit_transform(X_transformed)\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "        for train_ix, test_ix in loo.split(Y):\n",
    "            # split data\n",
    "            X_train, X_test = X_transformed[train_ix, :], X_transformed[test_ix, :]\n",
    "            y_train, y_test = Y[train_ix], Y[test_ix]\n",
    "            \n",
    "            # fit model\n",
    "            model = LogisticRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # evaluate model\n",
    "            yhat = model.predict(X_test)\n",
    "            # store\n",
    "            y_true.append(y_test[0])\n",
    "            y_pred.append(yhat[0])\n",
    "        \n",
    "        # calculate accuracy\n",
    "        acc = accuracy_score(y_true, y_pred)\n",
    "        print('Accuracy: %.3f' % acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XDawnLRModel()\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XDawnLRModel()\n",
    "model.fit(X_train, Y_train)\n",
    "#return model\n",
    "Y_pred = model.predict(X_test)\n",
    "print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(Y_test == Y_pred)/len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
